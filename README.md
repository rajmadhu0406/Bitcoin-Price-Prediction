Bitcoin is the world's first distributed digital currency, proposed and established by Satoshi Nakamoto in 2009. Since then, it has become an essential decentralized financial asset. Bitcoin offers tremendous potential returns but comes with high risks. Predicting Bitcoin prices can help investors and individuals earn substantial profits, but the high volatility of the Bitcoin market makes forecasting its price very difficult. Various models have been proposed for predicting Bitcoin prices, such as ARIMA, LSTM, GRU, and ANN. However, many of these models are trained on small datasets or cannot efficiently capture long-range dependencies.

This paper proposes a Transformer-LSTM ensemble model. The Transformer model, based on the paper "Attention Is All You Need," uses self-attention to capture long-range dependencies. The proposed model was trained on nearly nine years of historical Bitcoin prices and can efficiently capture long-range dependencies. It performs better than most deep learning models, achieving a RMSE error of 181.1013, one of the lowest error rates.






